{
  "adw_id": "d683d74a",
  "worktree_path": "/Users/Warmonger0/tac/tac-webbuilder/trees/d683d74a",
  "created_at": "2025-12-22T16:04:02.613033",
  "changed_files": [
    ".adw-context.json",
    ".mcp.json",
    "adws/adw_build_iso.py",
    "adws/adw_lint_iso.py",
    "adws/adw_modules/data_types.py",
    "adws/adw_modules/state.py",
    "adws/adw_test_iso.py",
    "adws/tests/test_data_types.py",
    "adws/tests/test_external_results_persistence.py"
  ],
  "target_files": [
    "adws/adw_modules/data_types.py",
    "adws/adw_modules/state.py",
    "adws/tests/test_data_types.py"
  ],
  "preloaded_content": {
    "adws/adw_modules/data_types.py": "\"\"\"Data types for GitHub API responses and Claude Code agent.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Optional, List, Literal\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\n\n\n# Retry codes for Claude Code execution errors\nclass RetryCode(str, Enum):\n    \"\"\"Codes indicating different types of errors that may be retryable.\"\"\"\n\n    CLAUDE_CODE_ERROR = \"claude_code_error\"  # General Claude Code CLI error\n    TIMEOUT_ERROR = \"timeout_error\"  # Command timed out\n    EXECUTION_ERROR = \"execution_error\"  # Error during execution\n    ERROR_DURING_EXECUTION = \"error_during_execution\"  # Agent encountered an error\n    NONE = \"none\"  # No retry needed\n\n\n# Supported slash commands for issue classification\n# These should align with your custom slash commands in .claude/commands that you want to run\nIssueClassSlashCommand = Literal[\"/chore\", \"/bug\", \"/feature\", \"/patch\"]\n\n# Model set types for ADW workflows\n# lightweight = Haiku (cheap, fast), base = Sonnet (smart), heavy = Opus (most capable)\nModelSet = Literal[\"base\", \"heavy\", \"lightweight\"]\n\n# ADW workflow types (all isolated now)\nADWWorkflow = Literal[\n    \"adw_plan_iso\",  # Planning only\n    \"adw_patch_iso\",  # Direct patch from issue\n    \"adw_build_iso\",  # Building only (dependent workflow)\n    \"adw_test_iso\",  # Testing only (dependent workflow)\n    \"adw_review_iso\",  # Review only (dependent workflow)\n    \"adw_document_iso\",  # Documentation only (dependent workflow)\n    \"adw_ship_iso\",  # Ship/deployment workflow\n    \"adw_sdlc_ZTE_iso\",  # Zero Touch Execution - full SDLC with auto-merge\n    \"adw_plan_build_iso\",  # Plan + Build\n    \"adw_plan_build_test_iso\",  # Plan + Build + Test\n    \"adw_plan_build_test_review_iso\",  # Plan + Build + Test + Review\n    \"adw_plan_build_document_iso\",  # Plan + Build + Document\n    \"adw_plan_build_review_iso\",  # Plan + Build + Review\n    \"adw_sdlc_iso\",  # Complete SDLC: Plan + Build + Test + Review + Document\n]\n\n# All slash commands used in the ADW system\n# Includes issue classification commands and ADW-specific commands\nSlashCommand = Literal[\n    # Issue classification commands\n    \"/chore\",\n    \"/bug\",\n    \"/feature\",\n    # ADW workflow commands\n    \"/classify_issue\",\n    \"/classify_adw\",\n    \"/generate_branch_name\",\n    \"/commit\",\n    \"/pull_request\",\n    \"/implement\",\n    \"/test\",\n    \"/resolve_failed_test\",\n    \"/test_e2e\",\n    \"/resolve_failed_e2e_test\",\n    \"/review\",\n    \"/patch\",\n    \"/document\",\n    \"/track_agentic_kpis\",\n    # Installation/setup commands\n    \"/install_worktree\",\n]\n\n\nclass GitHubUser(BaseModel):\n    \"\"\"GitHub user model.\"\"\"\n\n    id: Optional[str] = None  # Not always returned by GitHub API\n    login: str\n    name: Optional[str] = None\n    is_bot: bool = Field(default=False, alias=\"is_bot\")\n\n\nclass GitHubLabel(BaseModel):\n    \"\"\"GitHub label model.\"\"\"\n\n    id: str\n    name: str\n    color: str\n    description: Optional[str] = None\n\n\nclass GitHubMilestone(BaseModel):\n    \"\"\"GitHub milestone model.\"\"\"\n\n    id: str\n    number: int\n    title: str\n    description: Optional[str] = None\n    state: str\n\n\nclass GitHubComment(BaseModel):\n    \"\"\"GitHub comment model.\"\"\"\n\n    id: str\n    author: GitHubUser\n    body: str\n    created_at: datetime = Field(alias=\"createdAt\")\n    updated_at: Optional[datetime] = Field(\n        None, alias=\"updatedAt\"\n    )  # Not always returned\n\n\nclass GitHubIssueListItem(BaseModel):\n    \"\"\"GitHub issue model for list responses (simplified).\"\"\"\n\n    number: int\n    title: str\n    body: str\n    labels: List[GitHubLabel] = []\n    created_at: datetime = Field(alias=\"createdAt\")\n    updated_at: datetime = Field(alias=\"updatedAt\")\n\n    class Config:\n        populate_by_name = True\n\n\nclass GitHubIssue(BaseModel):\n    \"\"\"GitHub issue model.\"\"\"\n\n    number: int\n    title: str\n    body: str\n    state: str\n    author: GitHubUser\n    assignees: List[GitHubUser] = []\n    labels: List[GitHubLabel] = []\n    milestone: Optional[GitHubMilestone] = None\n    comments: List[GitHubComment] = []\n    created_at: datetime = Field(alias=\"createdAt\")\n    updated_at: datetime = Field(alias=\"updatedAt\")\n    closed_at: Optional[datetime] = Field(None, alias=\"closedAt\")\n    url: str\n\n    class Config:\n        populate_by_name = True\n\n\nclass AgentPromptRequest(BaseModel):\n    \"\"\"Claude Code agent prompt configuration.\"\"\"\n\n    prompt: str\n    adw_id: str\n    agent_name: str = \"ops\"\n    model: Literal[\"sonnet\", \"opus\"] = \"sonnet\"\n    dangerously_skip_permissions: bool = False\n    output_file: str\n    working_dir: Optional[str] = None\n\n\nclass AgentPromptResponse(BaseModel):\n    \"\"\"Claude Code agent response.\"\"\"\n\n    output: str\n    success: bool\n    session_id: Optional[str] = None\n    retry_code: RetryCode = RetryCode.NONE\n\n\nclass AgentTemplateRequest(BaseModel):\n    \"\"\"Claude Code agent template execution request.\"\"\"\n\n    agent_name: str\n    slash_command: SlashCommand\n    args: List[str]\n    adw_id: str\n    model: Literal[\"sonnet\", \"opus\"] = \"sonnet\"\n    working_dir: Optional[str] = None\n\n\nclass ClaudeCodeResultMessage(BaseModel):\n    \"\"\"Claude Code JSONL result message (last line).\"\"\"\n\n    type: str\n    subtype: str\n    is_error: bool\n    duration_ms: int\n    duration_api_ms: int\n    num_turns: int\n    result: str\n    session_id: str\n    total_cost_usd: float\n\n\nclass TestResult(BaseModel):\n    \"\"\"Individual test result from test suite execution.\"\"\"\n\n    test_name: str\n    passed: bool\n    execution_command: str\n    test_purpose: str\n    error: Optional[str] = None\n\n\nclass E2ETestResult(BaseModel):\n    \"\"\"Individual E2E test result from browser automation.\"\"\"\n\n    test_name: str\n    status: Literal[\"passed\", \"failed\"]\n    test_path: str  # Path to the test file for re-execution\n    screenshots: List[str] = []\n    error: Optional[str] = None\n\n    @property\n    def passed(self) -> bool:\n        \"\"\"Check if test passed.\"\"\"\n        return self.status == \"passed\"\n\n\nclass ADWStateData(BaseModel):\n    \"\"\"Minimal persistent state for ADW workflow.\n\n    Stored in agents/{adw_id}/adw_state.json\n    Contains ONLY execution metadata (paths, ports, outputs).\n\n    IMPORTANT: Coordination state (status, current_phase) is stored in the database\n    (phase_queue table). This file is NOT the source of truth for workflow status.\n    See docs/adw/state-management-ssot.md for complete SSoT rules.\n    \"\"\"\n\n    adw_id: str\n    issue_number: Optional[str] = None\n    branch_name: Optional[str] = None\n    plan_file: Optional[str] = None\n    issue_class: Optional[IssueClassSlashCommand] = None\n    worktree_path: Optional[str] = None\n    backend_port: Optional[int] = None\n    frontend_port: Optional[int] = None\n    model_set: Optional[ModelSet] = \"base\"  # Default to \"base\" model set\n    all_adws: List[str] = Field(default_factory=list)\n\n    # Cost tracking fields\n    estimated_cost_total: Optional[float] = None\n    estimated_cost_breakdown: Optional[dict] = None  # Per-phase estimates\n\n    # Workflow context metadata (NOT coordination state)\n    workflow_template: Optional[str] = None  # e.g., \"adw_sdlc_complete_zte_iso\"\n    model_used: Optional[str] = None  # e.g., \"sonnet\", \"haiku\", \"opus\"\n    start_time: Optional[str] = None  # ISO format timestamp\n    nl_input: Optional[str] = None  # Natural language input from user\n    github_url: Optional[str] = None  # GitHub issue URL\n\n    # Multi-stage analysis results (Phase 1 extensions)\n    component_analysis: Optional[\"ComponentAnalysis\"] = None\n    dry_findings: Optional[List[\"DRYFinding\"]] = None\n    context_analysis: Optional[\"ContextAnalysis\"] = None\n    multi_stage_metadata: Optional[dict] = None  # Flexible field for future extensions\n\n    # NOTE: 'status' and 'current_phase' removed - Database is SSoT for coordination\n    # Use PhaseQueueRepository to read/write workflow status and current phase\n\n\nclass ReviewIssue(BaseModel):\n    \"\"\"Individual review issue found during spec verification.\"\"\"\n\n    review_issue_number: int\n    screenshot_path: str  # Local file path to screenshot (e.g., \"agents/ADW-123/reviewer/review_img/error.png\")\n    screenshot_url: Optional[str] = (\n        None  # Public URL after upload (e.g., \"https://domain.com/adw/ADW-123/review/error.png\")\n    )\n    issue_description: str\n    issue_resolution: str\n    issue_severity: Literal[\"skippable\", \"tech_debt\", \"blocker\"]\n\n\nclass ReviewResult(BaseModel):\n    \"\"\"Result from reviewing implementation against specification.\"\"\"\n\n    success: bool\n    review_summary: (\n        str  # 2-4 sentences describing what was built and whether it matches the spec\n    )\n    review_issues: List[ReviewIssue] = []\n    screenshots: List[str] = (\n        []\n    )  # Local file paths (e.g., [\"agents/ADW-123/reviewer/review_img/ui.png\"])\n    screenshot_urls: List[str] = (\n        []\n    )  # Public URLs after upload, indexed-aligned with screenshots\n\n\nclass DocumentationResult(BaseModel):\n    \"\"\"Result from documentation generation workflow.\"\"\"\n\n    success: bool\n    documentation_created: bool\n    documentation_path: Optional[str] = None\n    error_message: Optional[str] = None\n\n\nclass ADWExtractionResult(BaseModel):\n    \"\"\"Result from extracting ADW information from text.\"\"\"\n\n    workflow_command: Optional[str] = None  # e.g., \"adw_plan_iso\" (without slash)\n    adw_id: Optional[str] = None  # 8-character ADW ID\n    model_set: Optional[ModelSet] = \"base\"  # Model set to use, defaults to \"base\"\n\n    @property\n    def has_workflow(self) -> bool:\n        \"\"\"Check if a workflow command was extracted.\"\"\"\n        return self.workflow_command is not None\n\n\n# Component types for ComponentAnalysis\nclass ComponentType(str, Enum):\n    \"\"\"Types of software components.\"\"\"\n\n    FRONTEND = \"frontend\"\n    BACKEND = \"backend\"\n    DATABASE = \"database\"\n    API = \"api\"\n    UTILITY = \"utility\"\n    TEST = \"test\"\n\n\nclass ComponentAnalysis(BaseModel):\n    \"\"\"Component-level analysis with complexity and dependencies.\"\"\"\n\n    component_type: ComponentType\n    complexity_score: float = Field(ge=0.0, le=1.0)  # Must be between 0.0 and 1.0\n    dependencies: List[str] = Field(default_factory=list)\n    lines_of_code: int = Field(ge=0)\n    file_count: int = Field(ge=0)\n    reasoning: str\n\n    @property\n    def is_frontend(self) -> bool:\n        \"\"\"Check if component is frontend type.\"\"\"\n        return self.component_type == ComponentType.FRONTEND\n\n    @property\n    def is_backend(self) -> bool:\n        \"\"\"Check if component is backend type.\"\"\"\n        return self.component_type == ComponentType.BACKEND\n\n\n# DRY violation severity levels\nclass DRYSeverity(str, Enum):\n    \"\"\"Severity levels for DRY violations.\"\"\"\n\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n\nclass DRYFinding(BaseModel):\n    \"\"\"DRY (Don't Repeat Yourself) violation finding.\"\"\"\n\n    severity: DRYSeverity\n    pattern_description: str\n    occurrences: int = Field(gt=0)  # Must be at least 1\n    locations: List[str]  # Format: \"file.py:line\"\n    suggested_refactor: Optional[str] = None\n    estimated_savings_loc: int = Field(ge=0)\n\n    @property\n    def is_critical(self) -> bool:\n        \"\"\"Check if severity is critical.\"\"\"\n        return self.severity == DRYSeverity.CRITICAL\n\n    @property\n    def is_high(self) -> bool:\n        \"\"\"Check if severity is high.\"\"\"\n        return self.severity == DRYSeverity.HIGH\n\n\n# Analysis scope levels\nclass AnalysisScope(str, Enum):\n    \"\"\"Scope levels for contextual analysis.\"\"\"\n\n    FILE = \"file\"\n    MODULE = \"module\"\n    SUBSYSTEM = \"subsystem\"\n    SYSTEM = \"system\"\n\n\nclass ContextAnalysis(BaseModel):\n    \"\"\"Contextual impact analysis for code changes.\"\"\"\n\n    scope: AnalysisScope\n    affected_files: List[str] = Field(default_factory=list)\n    integration_points: List[str] = Field(default_factory=list)\n    risk_assessment: str\n    test_coverage_required: bool\n    estimated_impact_loc: int = Field(ge=0)\n\n    @property\n    def is_system_wide(self) -> bool:\n        \"\"\"Check if scope is system-wide.\"\"\"\n        return self.scope == AnalysisScope.SYSTEM\n\n    @property\n    def requires_integration_tests(self) -> bool:\n        \"\"\"Check if integration tests are needed based on scope.\"\"\"\n        return self.scope in (AnalysisScope.SUBSYSTEM, AnalysisScope.SYSTEM)\n",
    "adws/adw_modules/state.py": "\"\"\"State management for ADW composable architecture.\n\nProvides persistent state management via file storage and\ntransient state passing between scripts via stdin/stdout.\n\"\"\"\n\nimport json\nimport os\nimport sys\nimport logging\nfrom typing import Dict, Any, Optional\nfrom adw_modules.data_types import ADWStateData\n\n\nclass ADWState:\n    \"\"\"Container for ADW workflow state with file persistence.\"\"\"\n\n    STATE_FILENAME = \"adw_state.json\"\n\n    def __init__(self, adw_id: str):\n        \"\"\"Initialize ADWState with a required ADW ID.\n        \n        Args:\n            adw_id: The ADW ID for this state (required)\n        \"\"\"\n        if not adw_id:\n            raise ValueError(\"adw_id is required for ADWState\")\n        \n        self.adw_id = adw_id\n        # Start with minimal state\n        self.data: Dict[str, Any] = {\"adw_id\": self.adw_id}\n        self.logger = logging.getLogger(__name__)\n\n    def update(self, **kwargs):\n        \"\"\"Update state with new key-value pairs.\n\n        IMPORTANT: Does NOT accept 'status' or 'current_phase' - these are coordination\n        state fields that belong in the database. Use PhaseQueueRepository for those.\n        See docs/adw/state-management-ssot.md for complete SSoT rules.\n        \"\"\"\n        # Core execution metadata fields (NOT coordination state)\n        core_fields = {\n            \"adw_id\", \"issue_number\", \"branch_name\", \"plan_file\", \"issue_class\",\n            \"worktree_path\", \"backend_port\", \"frontend_port\", \"model_set\", \"all_adws\",\n            \"estimated_cost_total\", \"estimated_cost_breakdown\",\n            # Workflow context metadata\n            \"workflow_template\", \"model_used\", \"start_time\", \"end_time\", \"nl_input\", \"github_url\",\n            # Phase output metadata\n            \"baseline_errors\", \"external_build_results\", \"external_lint_results\",\n            \"external_test_results\", \"review_results\", \"integration_checklist\",\n            \"integration_checklist_markdown\",\n            # Multi-stage analysis results (Phase 1 extensions)\n            \"component_analysis\", \"dry_findings\", \"context_analysis\", \"multi_stage_metadata\"\n        }\n\n        # Validate no forbidden fields (SSoT enforcement)\n        forbidden_fields = {\"status\", \"current_phase\"}\n        for key in kwargs:\n            if key in forbidden_fields:\n                raise ValueError(\n                    f\"Cannot update '{key}' in state file. Database is SSoT for coordination state. \"\n                    f\"Use PhaseQueueRepository.update_status() instead. \"\n                    f\"See docs/adw/state-management-ssot.md\"\n                )\n\n        for key, value in kwargs.items():\n            if key in core_fields:\n                self.data[key] = value\n\n    def get(self, key: str, default=None):\n        \"\"\"Get value from state by key.\"\"\"\n        return self.data.get(key, default)\n\n    def append_adw_id(self, adw_id: str):\n        \"\"\"Append an ADW ID to the all_adws list if not already present.\"\"\"\n        all_adws = self.data.get(\"all_adws\", [])\n        if adw_id not in all_adws:\n            all_adws.append(adw_id)\n            self.data[\"all_adws\"] = all_adws\n\n    def get_working_directory(self) -> str:\n        \"\"\"Get the working directory for this ADW instance.\n        \n        Returns worktree_path if set (for isolated workflows),\n        otherwise returns the main repo path.\n        \"\"\"\n        worktree_path = self.data.get(\"worktree_path\")\n        if worktree_path:\n            return worktree_path\n        \n        # Return main repo path (parent of adws directory)\n        return os.path.dirname(\n            os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n        )\n\n    def get_state_path(self) -> str:\n        \"\"\"Get path to state file.\"\"\"\n        project_root = os.path.dirname(\n            os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n        )\n        return os.path.join(project_root, \"agents\", self.adw_id, self.STATE_FILENAME)\n\n    def save(self, workflow_step: Optional[str] = None) -> None:\n        \"\"\"Save state to file in agents/{adw_id}/adw_state.json.\n\n        IMPORTANT: Does NOT save 'status' or 'current_phase' - these belong in database.\n        See docs/adw/state-management-ssot.md for complete SSoT rules.\n        \"\"\"\n        state_path = self.get_state_path()\n        os.makedirs(os.path.dirname(state_path), exist_ok=True)\n\n        # Validate no forbidden fields before saving (SSoT enforcement)\n        forbidden_fields = {\"status\", \"current_phase\"}\n        found_forbidden = [f for f in forbidden_fields if f in self.data]\n        if found_forbidden:\n            raise ValueError(\n                f\"Cannot save state with forbidden fields: {found_forbidden}. \"\n                f\"These are coordination state fields that belong in database. \"\n                f\"Use PhaseQueueRepository for status/current_phase. \"\n                f\"See docs/adw/state-management-ssot.md\"\n            )\n\n        # Create ADWStateData for validation of core execution metadata fields\n        state_data = ADWStateData(\n            adw_id=self.data.get(\"adw_id\"),\n            issue_number=self.data.get(\"issue_number\"),\n            branch_name=self.data.get(\"branch_name\"),\n            plan_file=self.data.get(\"plan_file\"),\n            issue_class=self.data.get(\"issue_class\"),\n            worktree_path=self.data.get(\"worktree_path\"),\n            backend_port=self.data.get(\"backend_port\"),\n            frontend_port=self.data.get(\"frontend_port\"),\n            model_set=self.data.get(\"model_set\", \"base\"),\n            all_adws=self.data.get(\"all_adws\", []),\n            estimated_cost_total=self.data.get(\"estimated_cost_total\"),\n            estimated_cost_breakdown=self.data.get(\"estimated_cost_breakdown\"),\n            # Workflow context metadata (NOT coordination state)\n            workflow_template=self.data.get(\"workflow_template\"),\n            model_used=self.data.get(\"model_used\"),\n            start_time=self.data.get(\"start_time\"),\n            nl_input=self.data.get(\"nl_input\"),\n            github_url=self.data.get(\"github_url\"),\n            # Multi-stage analysis results (Phase 1 extensions)\n            component_analysis=self.data.get(\"component_analysis\"),\n            dry_findings=self.data.get(\"dry_findings\"),\n            context_analysis=self.data.get(\"context_analysis\"),\n            multi_stage_metadata=self.data.get(\"multi_stage_metadata\"),\n        )\n\n        # Start with validated core fields\n        save_data = state_data.model_dump()\n\n        # Add extra fields (like external_build_results, external_test_results, etc.)\n        core_field_names = set(state_data.model_fields.keys())\n        for key, value in self.data.items():\n            if key not in core_field_names:\n                # Double-check no forbidden fields slip through\n                if key in forbidden_fields:\n                    continue  # Skip forbidden fields silently\n                save_data[key] = value\n\n        # Save as JSON\n        with open(state_path, \"w\") as f:\n            json.dump(save_data, f, indent=2)\n\n        self.logger.info(f\"Saved state to {state_path}\")\n        if workflow_step:\n            self.logger.info(f\"State updated by: {workflow_step}\")\n\n    @classmethod\n    def load(\n        cls, adw_id: str, logger: Optional[logging.Logger] = None\n    ) -> Optional[\"ADWState\"]:\n        \"\"\"Load state from file if it exists.\"\"\"\n        project_root = os.path.dirname(\n            os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n        )\n        state_path = os.path.join(project_root, \"agents\", adw_id, cls.STATE_FILENAME)\n\n        if not os.path.exists(state_path):\n            return None\n\n        try:\n            with open(state_path, \"r\") as f:\n                data = json.load(f)\n\n            # Validate core fields with ADWStateData\n            # This will raise an error if core fields are invalid\n            state_data = ADWStateData(**{k: v for k, v in data.items() if k in ADWStateData.model_fields})\n\n            # Create ADWState instance\n            state = cls(state_data.adw_id)\n            # Use full data to preserve extra fields (like external_build_results)\n            state.data = data\n\n            if logger:\n                logger.info(f\"\ud83d\udd0d Found existing state from {state_path}\")\n                logger.info(f\"State: {json.dumps(data, indent=2)}\")\n\n            return state\n        except Exception as e:\n            if logger:\n                logger.error(f\"Failed to load state from {state_path}: {e}\")\n            return None\n\n    @classmethod\n    def from_stdin(cls) -> Optional[\"ADWState\"]:\n        \"\"\"Read state from stdin if available (for piped input).\n\n        Returns None if no piped input is available (stdin is a tty).\n        \"\"\"\n        if sys.stdin.isatty():\n            return None\n        try:\n            input_data = sys.stdin.read()\n            if not input_data.strip():\n                return None\n            data = json.loads(input_data)\n            adw_id = data.get(\"adw_id\")\n            if not adw_id:\n                return None  # No valid state without adw_id\n            state = cls(adw_id)\n            state.data = data\n            return state\n        except (json.JSONDecodeError, EOFError):\n            return None\n\n    def to_stdout(self):\n        \"\"\"Write state to stdout as JSON (for piping to next script).\"\"\"\n        # Only output core fields\n        output_data = {\n            \"adw_id\": self.data.get(\"adw_id\"),\n            \"issue_number\": self.data.get(\"issue_number\"),\n            \"branch_name\": self.data.get(\"branch_name\"),\n            \"plan_file\": self.data.get(\"plan_file\"),\n            \"issue_class\": self.data.get(\"issue_class\"),\n            \"worktree_path\": self.data.get(\"worktree_path\"),\n            \"backend_port\": self.data.get(\"backend_port\"),\n            \"frontend_port\": self.data.get(\"frontend_port\"),\n            \"all_adws\": self.data.get(\"all_adws\", []),\n        }\n        print(json.dumps(output_data, indent=2))\n",
    "adws/tests/test_data_types.py": "\"\"\"Unit tests for data_types.py multi-stage analysis dataclasses.\"\"\"\n\nimport pytest\nfrom pydantic import ValidationError\nfrom adw_modules.data_types import (\n    ComponentAnalysis,\n    ComponentType,\n    DRYFinding,\n    DRYSeverity,\n    ContextAnalysis,\n    AnalysisScope,\n    ADWStateData,\n)\n\n\nclass TestComponentAnalysis:\n    \"\"\"Tests for ComponentAnalysis dataclass.\"\"\"\n\n    def test_valid_component_analysis(self):\n        \"\"\"Test creating valid ComponentAnalysis.\"\"\"\n        component = ComponentAnalysis(\n            component_type=ComponentType.FRONTEND,\n            complexity_score=0.5,\n            dependencies=[\"react\", \"typescript\"],\n            lines_of_code=1000,\n            file_count=10,\n            reasoning=\"Component handles user authentication UI\",\n        )\n        assert component.component_type == ComponentType.FRONTEND\n        assert component.complexity_score == 0.5\n        assert len(component.dependencies) == 2\n        assert component.lines_of_code == 1000\n        assert component.file_count == 10\n\n    def test_invalid_component_type(self):\n        \"\"\"Test invalid component type raises validation error.\"\"\"\n        with pytest.raises(ValidationError) as exc_info:\n            ComponentAnalysis(\n                component_type=\"invalid_type\",\n                complexity_score=0.5,\n                dependencies=[],\n                lines_of_code=100,\n                file_count=1,\n                reasoning=\"test\",\n            )\n        assert \"component_type\" in str(exc_info.value)\n\n    def test_complexity_score_range_validation(self):\n        \"\"\"Test complexity score must be between 0.0 and 1.0.\"\"\"\n        # Valid boundaries\n        ComponentAnalysis(\n            component_type=ComponentType.BACKEND,\n            complexity_score=0.0,\n            dependencies=[],\n            lines_of_code=50,\n            file_count=1,\n            reasoning=\"minimal component\",\n        )\n        ComponentAnalysis(\n            component_type=ComponentType.BACKEND,\n            complexity_score=1.0,\n            dependencies=[],\n            lines_of_code=5000,\n            file_count=50,\n            reasoning=\"complex component\",\n        )\n\n        # Invalid: below range\n        with pytest.raises(ValidationError):\n            ComponentAnalysis(\n                component_type=ComponentType.BACKEND,\n                complexity_score=-0.1,\n                dependencies=[],\n                lines_of_code=50,\n                file_count=1,\n                reasoning=\"test\",\n            )\n\n        # Invalid: above range\n        with pytest.raises(ValidationError):\n            ComponentAnalysis(\n                component_type=ComponentType.BACKEND,\n                complexity_score=1.1,\n                dependencies=[],\n                lines_of_code=50,\n                file_count=1,\n                reasoning=\"test\",\n            )\n\n    def test_empty_dependencies_list(self):\n        \"\"\"Test that empty dependencies list is valid.\"\"\"\n        component = ComponentAnalysis(\n            component_type=ComponentType.UTILITY,\n            complexity_score=0.2,\n            dependencies=[],\n            lines_of_code=50,\n            file_count=1,\n            reasoning=\"standalone utility\",\n        )\n        assert component.dependencies == []\n\n    def test_property_methods(self):\n        \"\"\"Test convenience property methods.\"\"\"\n        frontend = ComponentAnalysis(\n            component_type=ComponentType.FRONTEND,\n            complexity_score=0.5,\n            dependencies=[],\n            lines_of_code=100,\n            file_count=5,\n            reasoning=\"test\",\n        )\n        assert frontend.is_frontend is True\n        assert frontend.is_backend is False\n\n        backend = ComponentAnalysis(\n            component_type=ComponentType.BACKEND,\n            complexity_score=0.7,\n            dependencies=[],\n            lines_of_code=200,\n            file_count=8,\n            reasoning=\"test\",\n        )\n        assert backend.is_backend is True\n        assert backend.is_frontend is False\n\n    def test_serialization(self):\n        \"\"\"Test serialization via model_dump().\"\"\"\n        component = ComponentAnalysis(\n            component_type=ComponentType.API,\n            complexity_score=0.6,\n            dependencies=[\"fastapi\", \"pydantic\"],\n            lines_of_code=500,\n            file_count=15,\n            reasoning=\"REST API implementation\",\n        )\n        data = component.model_dump()\n        assert data[\"component_type\"] == \"api\"\n        assert data[\"complexity_score\"] == 0.6\n        assert data[\"dependencies\"] == [\"fastapi\", \"pydantic\"]\n        assert data[\"lines_of_code\"] == 500\n        assert data[\"file_count\"] == 15\n\n    def test_deserialization(self):\n        \"\"\"Test deserialization via model_validate().\"\"\"\n        data = {\n            \"component_type\": \"database\",\n            \"complexity_score\": 0.8,\n            \"dependencies\": [\"sqlalchemy\", \"psycopg2\"],\n            \"lines_of_code\": 800,\n            \"file_count\": 20,\n            \"reasoning\": \"Database layer implementation\",\n        }\n        component = ComponentAnalysis.model_validate(data)\n        assert component.component_type == ComponentType.DATABASE\n        assert component.complexity_score == 0.8\n        assert component.dependencies == [\"sqlalchemy\", \"psycopg2\"]\n\n    def test_round_trip_serialization(self):\n        \"\"\"Test serialize \u2192 deserialize round-trip preserves data.\"\"\"\n        original = ComponentAnalysis(\n            component_type=ComponentType.TEST,\n            complexity_score=0.3,\n            dependencies=[\"pytest\", \"coverage\"],\n            lines_of_code=300,\n            file_count=12,\n            reasoning=\"Test suite implementation\",\n        )\n        data = original.model_dump()\n        restored = ComponentAnalysis.model_validate(data)\n        assert restored == original\n\n\nclass TestDRYFinding:\n    \"\"\"Tests for DRYFinding dataclass.\"\"\"\n\n    def test_valid_dry_finding(self):\n        \"\"\"Test creating valid DRYFinding.\"\"\"\n        finding = DRYFinding(\n            severity=DRYSeverity.HIGH,\n            pattern_description=\"Repeated authentication logic\",\n            occurrences=5,\n            locations=[\"auth.py:100\", \"user.py:250\", \"api.py:75\"],\n            suggested_refactor=\"Extract to auth_utils.py\",\n            estimated_savings_loc=120,\n        )\n        assert finding.severity == DRYSeverity.HIGH\n        assert finding.occurrences == 5\n        assert len(finding.locations) == 3\n\n    def test_invalid_severity(self):\n        \"\"\"Test invalid severity raises validation error.\"\"\"\n        with pytest.raises(ValidationError) as exc_info:\n            DRYFinding(\n                severity=\"super_critical\",\n                pattern_description=\"test\",\n                occurrences=2,\n                locations=[\"file.py:1\"],\n                estimated_savings_loc=10,\n            )\n        assert \"severity\" in str(exc_info.value)\n\n    def test_occurrences_must_be_positive(self):\n        \"\"\"Test occurrences must be at least 1.\"\"\"\n        # Valid: 1 occurrence\n        DRYFinding(\n            severity=DRYSeverity.LOW,\n            pattern_description=\"test\",\n            occurrences=1,\n            locations=[\"file.py:1\"],\n            estimated_savings_loc=5,\n        )\n\n        # Invalid: 0 occurrences\n        with pytest.raises(ValidationError):\n            DRYFinding(\n                severity=DRYSeverity.LOW,\n                pattern_description=\"test\",\n                occurrences=0,\n                locations=[],\n                estimated_savings_loc=0,\n            )\n\n        # Invalid: negative occurrences\n        with pytest.raises(ValidationError):\n            DRYFinding(\n                severity=DRYSeverity.LOW,\n                pattern_description=\"test\",\n                occurrences=-1,\n                locations=[],\n                estimated_savings_loc=0,\n            )\n\n    def test_optional_suggested_refactor(self):\n        \"\"\"Test suggested_refactor is optional.\"\"\"\n        finding = DRYFinding(\n            severity=DRYSeverity.MEDIUM,\n            pattern_description=\"Duplicate validation\",\n            occurrences=3,\n            locations=[\"a.py:10\", \"b.py:20\"],\n            estimated_savings_loc=30,\n        )\n        assert finding.suggested_refactor is None\n\n    def test_property_methods(self):\n        \"\"\"Test severity property methods.\"\"\"\n        critical = DRYFinding(\n            severity=DRYSeverity.CRITICAL,\n            pattern_description=\"test\",\n            occurrences=10,\n            locations=[\"file.py:1\"],\n            estimated_savings_loc=500,\n        )\n        assert critical.is_critical is True\n        assert critical.is_high is False\n\n        high = DRYFinding(\n            severity=DRYSeverity.HIGH,\n            pattern_description=\"test\",\n            occurrences=5,\n            locations=[\"file.py:1\"],\n            estimated_savings_loc=100,\n        )\n        assert high.is_high is True\n        assert high.is_critical is False\n\n    def test_serialization(self):\n        \"\"\"Test serialization via model_dump().\"\"\"\n        finding = DRYFinding(\n            severity=DRYSeverity.MEDIUM,\n            pattern_description=\"Repeated error handling\",\n            occurrences=4,\n            locations=[\"handler1.py:50\", \"handler2.py:75\"],\n            suggested_refactor=\"Create error_handler_utils.py\",\n            estimated_savings_loc=80,\n        )\n        data = finding.model_dump()\n        assert data[\"severity\"] == \"medium\"\n        assert data[\"pattern_description\"] == \"Repeated error handling\"\n        assert data[\"occurrences\"] == 4\n        assert len(data[\"locations\"]) == 2\n\n    def test_deserialization(self):\n        \"\"\"Test deserialization via model_validate().\"\"\"\n        data = {\n            \"severity\": \"low\",\n            \"pattern_description\": \"Minor duplication\",\n            \"occurrences\": 2,\n            \"locations\": [\"a.py:10\"],\n            \"estimated_savings_loc\": 15,\n        }\n        finding = DRYFinding.model_validate(data)\n        assert finding.severity == DRYSeverity.LOW\n        assert finding.occurrences == 2\n\n    def test_round_trip_serialization(self):\n        \"\"\"Test serialize \u2192 deserialize round-trip preserves data.\"\"\"\n        original = DRYFinding(\n            severity=DRYSeverity.CRITICAL,\n            pattern_description=\"Critical duplication\",\n            occurrences=8,\n            locations=[\"x.py:100\", \"y.py:200\", \"z.py:300\"],\n            suggested_refactor=\"Extract to shared module\",\n            estimated_savings_loc=400,\n        )\n        data = original.model_dump()\n        restored = DRYFinding.model_validate(data)\n        assert restored == original\n\n\nclass TestContextAnalysis:\n    \"\"\"Tests for ContextAnalysis dataclass.\"\"\"\n\n    def test_valid_context_analysis(self):\n        \"\"\"Test creating valid ContextAnalysis.\"\"\"\n        analysis = ContextAnalysis(\n            scope=AnalysisScope.SUBSYSTEM,\n            affected_files=[\"file1.py\", \"file2.py\", \"file3.py\"],\n            integration_points=[\"API Gateway\", \"Database Layer\"],\n            risk_assessment=\"Medium risk - requires integration testing\",\n            test_coverage_required=True,\n            estimated_impact_loc=250,\n        )\n        assert analysis.scope == AnalysisScope.SUBSYSTEM\n        assert len(analysis.affected_files) == 3\n        assert analysis.test_coverage_required is True\n\n    def test_invalid_scope(self):\n        \"\"\"Test invalid scope raises validation error.\"\"\"\n        with pytest.raises(ValidationError) as exc_info:\n            ContextAnalysis(\n                scope=\"global\",\n                affected_files=[],\n                integration_points=[],\n                risk_assessment=\"test\",\n                test_coverage_required=False,\n                estimated_impact_loc=10,\n            )\n        assert \"scope\" in str(exc_info.value)\n\n    def test_empty_lists_valid(self):\n        \"\"\"Test empty affected_files and integration_points lists are valid.\"\"\"\n        analysis = ContextAnalysis(\n            scope=AnalysisScope.FILE,\n            affected_files=[],\n            integration_points=[],\n            risk_assessment=\"Low risk - isolated change\",\n            test_coverage_required=False,\n            estimated_impact_loc=5,\n        )\n        assert analysis.affected_files == []\n        assert analysis.integration_points == []\n\n    def test_property_methods(self):\n        \"\"\"Test scope property methods.\"\"\"\n        system = ContextAnalysis(\n            scope=AnalysisScope.SYSTEM,\n            affected_files=[\"many\", \"files\", \"here\"],\n            integration_points=[\"API\", \"DB\", \"Cache\"],\n            risk_assessment=\"High risk\",\n            test_coverage_required=True,\n            estimated_impact_loc=1000,\n        )\n        assert system.is_system_wide is True\n        assert system.requires_integration_tests is True\n\n        file_scope = ContextAnalysis(\n            scope=AnalysisScope.FILE,\n            affected_files=[\"single.py\"],\n            integration_points=[],\n            risk_assessment=\"Low risk\",\n            test_coverage_required=False,\n            estimated_impact_loc=10,\n        )\n        assert file_scope.is_system_wide is False\n        assert file_scope.requires_integration_tests is False\n\n        subsystem = ContextAnalysis(\n            scope=AnalysisScope.SUBSYSTEM,\n            affected_files=[\"a.py\", \"b.py\"],\n            integration_points=[\"API\"],\n            risk_assessment=\"Medium risk\",\n            test_coverage_required=True,\n            estimated_impact_loc=100,\n        )\n        assert subsystem.requires_integration_tests is True\n\n    def test_serialization(self):\n        \"\"\"Test serialization via model_dump().\"\"\"\n        analysis = ContextAnalysis(\n            scope=AnalysisScope.MODULE,\n            affected_files=[\"module_a.py\", \"module_b.py\"],\n            integration_points=[\"Service Layer\"],\n            risk_assessment=\"Medium risk - module-wide changes\",\n            test_coverage_required=True,\n            estimated_impact_loc=150,\n        )\n        data = analysis.model_dump()\n        assert data[\"scope\"] == \"module\"\n        assert len(data[\"affected_files\"]) == 2\n        assert data[\"test_coverage_required\"] is True\n\n    def test_deserialization(self):\n        \"\"\"Test deserialization via model_validate().\"\"\"\n        data = {\n            \"scope\": \"system\",\n            \"affected_files\": [\"f1.py\", \"f2.py\", \"f3.py\"],\n            \"integration_points\": [\"API\", \"DB\"],\n            \"risk_assessment\": \"High risk\",\n            \"test_coverage_required\": True,\n            \"estimated_impact_loc\": 500,\n        }\n        analysis = ContextAnalysis.model_validate(data)\n        assert analysis.scope == AnalysisScope.SYSTEM\n        assert len(analysis.affected_files) == 3\n\n    def test_round_trip_serialization(self):\n        \"\"\"Test serialize \u2192 deserialize round-trip preserves data.\"\"\"\n        original = ContextAnalysis(\n            scope=AnalysisScope.FILE,\n            affected_files=[\"single_file.py\"],\n            integration_points=[],\n            risk_assessment=\"Low risk - isolated file change\",\n            test_coverage_required=False,\n            estimated_impact_loc=25,\n        )\n        data = original.model_dump()\n        restored = ContextAnalysis.model_validate(data)\n        assert restored == original\n\n\nclass TestADWStateDataExtensions:\n    \"\"\"Tests for ADWStateData with multi-stage analysis fields.\"\"\"\n\n    def test_state_without_analysis_fields(self):\n        \"\"\"Test backward compatibility - state without analysis fields.\"\"\"\n        state = ADWStateData(adw_id=\"test-123\")\n        assert state.adw_id == \"test-123\"\n        assert state.component_analysis is None\n        assert state.dry_findings is None\n        assert state.context_analysis is None\n        assert state.multi_stage_metadata is None\n\n    def test_state_with_component_analysis(self):\n        \"\"\"Test state with component_analysis field.\"\"\"\n        component = ComponentAnalysis(\n            component_type=ComponentType.BACKEND,\n            complexity_score=0.7,\n            dependencies=[\"fastapi\"],\n            lines_of_code=500,\n            file_count=10,\n            reasoning=\"Backend API implementation\",\n        )\n        state = ADWStateData(adw_id=\"test-456\", component_analysis=component)\n        assert state.component_analysis is not None\n        assert state.component_analysis.component_type == ComponentType.BACKEND\n\n    def test_state_with_dry_findings(self):\n        \"\"\"Test state with dry_findings list.\"\"\"\n        findings = [\n            DRYFinding(\n                severity=DRYSeverity.HIGH,\n                pattern_description=\"Auth duplication\",\n                occurrences=3,\n                locations=[\"a.py:10\", \"b.py:20\"],\n                estimated_savings_loc=50,\n            ),\n            DRYFinding(\n                severity=DRYSeverity.MEDIUM,\n                pattern_description=\"Validation duplication\",\n                occurrences=2,\n                locations=[\"x.py:30\"],\n                estimated_savings_loc=20,\n            ),\n        ]\n        state = ADWStateData(adw_id=\"test-789\", dry_findings=findings)\n        assert state.dry_findings is not None\n        assert len(state.dry_findings) == 2\n        assert state.dry_findings[0].severity == DRYSeverity.HIGH\n\n    def test_state_with_context_analysis(self):\n        \"\"\"Test state with context_analysis field.\"\"\"\n        context = ContextAnalysis(\n            scope=AnalysisScope.SYSTEM,\n            affected_files=[\"file1.py\", \"file2.py\"],\n            integration_points=[\"API\", \"DB\"],\n            risk_assessment=\"High risk\",\n            test_coverage_required=True,\n            estimated_impact_loc=300,\n        )\n        state = ADWStateData(adw_id=\"test-999\", context_analysis=context)\n        assert state.context_analysis is not None\n        assert state.context_analysis.scope == AnalysisScope.SYSTEM\n\n    def test_state_with_multi_stage_metadata(self):\n        \"\"\"Test state with multi_stage_metadata dict.\"\"\"\n        metadata = {\n            \"analysis_version\": \"1.0\",\n            \"timestamp\": \"2025-12-22T10:00:00Z\",\n            \"analyzer_agent\": \"complexity_analyzer\",\n        }\n        state = ADWStateData(adw_id=\"test-meta\", multi_stage_metadata=metadata)\n        assert state.multi_stage_metadata is not None\n        assert state.multi_stage_metadata[\"analysis_version\"] == \"1.0\"\n\n    def test_state_serialization_with_analysis_fields(self):\n        \"\"\"Test serialization of state with all analysis fields.\"\"\"\n        component = ComponentAnalysis(\n            component_type=ComponentType.FRONTEND,\n            complexity_score=0.5,\n            dependencies=[\"react\"],\n            lines_of_code=200,\n            file_count=5,\n            reasoning=\"UI component\",\n        )\n        findings = [\n            DRYFinding(\n                severity=DRYSeverity.LOW,\n                pattern_description=\"Minor duplication\",\n                occurrences=2,\n                locations=[\"a.py:1\"],\n                estimated_savings_loc=10,\n            )\n        ]\n        context = ContextAnalysis(\n            scope=AnalysisScope.MODULE,\n            affected_files=[\"module.py\"],\n            integration_points=[],\n            risk_assessment=\"Low risk\",\n            test_coverage_required=False,\n            estimated_impact_loc=20,\n        )\n        state = ADWStateData(\n            adw_id=\"test-full\",\n            component_analysis=component,\n            dry_findings=findings,\n            context_analysis=context,\n            multi_stage_metadata={\"test\": \"data\"},\n        )\n        data = state.model_dump()\n        assert \"component_analysis\" in data\n        assert \"dry_findings\" in data\n        assert \"context_analysis\" in data\n        assert \"multi_stage_metadata\" in data\n        assert data[\"component_analysis\"][\"component_type\"] == \"frontend\"\n\n    def test_state_deserialization_with_missing_fields(self):\n        \"\"\"Test loading state from JSON with missing analysis fields defaults to None.\"\"\"\n        data = {\"adw_id\": \"test-minimal\"}\n        state = ADWStateData.model_validate(data)\n        assert state.adw_id == \"test-minimal\"\n        assert state.component_analysis is None\n        assert state.dry_findings is None\n        assert state.context_analysis is None\n\n    def test_state_round_trip_with_all_fields(self):\n        \"\"\"Test full round-trip with all analysis fields populated.\"\"\"\n        original = ADWStateData(\n            adw_id=\"round-trip-test\",\n            issue_number=\"123\",\n            branch_name=\"feature/test\",\n            component_analysis=ComponentAnalysis(\n                component_type=ComponentType.API,\n                complexity_score=0.8,\n                dependencies=[\"fastapi\"],\n                lines_of_code=600,\n                file_count=15,\n                reasoning=\"REST API\",\n            ),\n            dry_findings=[\n                DRYFinding(\n                    severity=DRYSeverity.CRITICAL,\n                    pattern_description=\"Critical dup\",\n                    occurrences=5,\n                    locations=[\"a.py:1\"],\n                    estimated_savings_loc=100,\n                )\n            ],\n            context_analysis=ContextAnalysis(\n                scope=AnalysisScope.SUBSYSTEM,\n                affected_files=[\"a.py\", \"b.py\"],\n                integration_points=[\"API\"],\n                risk_assessment=\"Medium\",\n                test_coverage_required=True,\n                estimated_impact_loc=150,\n            ),\n            multi_stage_metadata={\"version\": \"2.0\"},\n        )\n        data = original.model_dump()\n        restored = ADWStateData.model_validate(data)\n        assert restored.adw_id == original.adw_id\n        assert restored.component_analysis.component_type == ComponentType.API\n        assert len(restored.dry_findings) == 1\n        assert restored.context_analysis.scope == AnalysisScope.SUBSYSTEM\n        assert restored.multi_stage_metadata[\"version\"] == \"2.0\"\n"
  }
}